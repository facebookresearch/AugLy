{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ade83e4",
   "metadata": {},
   "source": [
    "# Robustness Report: Template\n",
    "Accuracy on a benchmark dataset is one measure of model performance. A model’s robustness to common data manipulations is a less commonly-used but important evaluation criterion. This notebook evaluates how robust imagenet models are to data augmentations from [AugLy](https://github.com/facebookresearch/AugLy). This notebook is designed to be easily reused to evaluate model robustness. Please refer to the instructions below to modify it as needed for your own model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb8b30",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook evaluates the robustness of the <TODO> model, trained on ImageNet, to 17 image modifications from the AugLy data augmentation library. These 17 modifications cover a diverse set of image manipulations, from blur and color jitter, to textual overlays. We report change in classification accuracy after applying these modifications, and compare the change in accuracy to 3 baseline models, VGG16, ResNet152, and Efficientnet-L2. Our results show that <TODO>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import timm\n",
    "import torch\n",
    "import augly.image as imaugs\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import save_image\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5507a",
   "metadata": {},
   "source": [
    "## Constants & set up\n",
    "If you want to run this notebook on another model, you may need to change constants in the 2 cells below this. The rest of the cells in this section are reusable code & set up that you should not need to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c65c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these constants corresponding to the model you want to evaluate!\n",
    "\n",
    "# The name of your model (loadable using `timm.create_model()`) or a\n",
    "# function to load your model (e.g. from `torchvision.models`)\n",
    "model_name = \"\"\n",
    "\n",
    "# The size your model expects images' width & height to be\n",
    "model_input_size = 800\n",
    "\n",
    "# The local dir where you have the imagenet validation dataset\n",
    "dataset_dir = \"\"\n",
    "\n",
    "# The local path where you have the imagenet val data table json file\n",
    "data_table_path = \"\"\n",
    "\n",
    "# The local dir where the imagenet val images will be augmented & stored\n",
    "aug_dataset_dir = \"\"\n",
    "\n",
    "# The local dir where the precomputed CSVs of metrics for\n",
    "# VGG/Resnet/Efficientnet are; if you have changed the seed or num_images\n",
    "# constants below then set this to None so the metrics are all re-computed;\n",
    "# otherwise the metrics will be loaded from the CSVs to avoid wasting\n",
    "# computation\n",
    "precomputed_model_metrics_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb23b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only change these constants if you have a reason to\n",
    "\n",
    "# Set to True if you want to recompute all the model metrics\n",
    "# (i.e. if you change the set of images you're evaluating on)\n",
    "recompute_model_metrics = False\n",
    "\n",
    "# Keeps the images sampled deterministic\n",
    "seed = 1245\n",
    "\n",
    "# The number of images to evaluate on\n",
    "num_images = 250\n",
    "\n",
    "# The number of images to run through each model at once; larger batch\n",
    "# size can cause CUDA to run out of memory depending how much memory\n",
    "# your GPUs have\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send model + inputs to different devices\n",
    "devices = [\n",
    "    torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100667ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing transformations which will be applied to all images\n",
    "base_transforms = [\n",
    "    lambda path: Image.open(path),\n",
    "    lambda image: image.convert(mode=\"RGB\"),\n",
    "    transforms.Resize(800),\n",
    "    transforms.CenterCrop(800),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "]\n",
    "\n",
    "# For the model input above, the image dimensions might be different\n",
    "custom_model_transforms = [\n",
    "    lambda path: Image.open(path),\n",
    "    lambda image: image.convert(mode=\"RGB\"),\n",
    "    transforms.Resize(model_input_size),\n",
    "    transforms.CenterCrop(model_input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "]\n",
    "\n",
    "# The augmentations we want to test robustness to\n",
    "augmentations = {\n",
    "    \"blur\": imaugs.Blur(radius=3),\n",
    "    \"random_noise\": imaugs.RandomNoise(mean=0.1, var=0.2),\n",
    "    \"sharpen\": imaugs.Sharpen(factor=10),\n",
    "    \"encoding_quality\": imaugs.EncodingQuality(quality=15),\n",
    "    \"change_aspect_ratio\": imaugs.ChangeAspectRatio(ratio=3.0),\n",
    "    \"opacity\": imaugs.Opacity(level=0.5),\n",
    "    \"pixelization\": imaugs.Pixelization(ratio=0.3),\n",
    "    \"scale\": imaugs.Scale(factor=0.5),\n",
    "    \"color_jitter\": imaugs.ColorJitter(\n",
    "        brightness_factor=1.6,\n",
    "        contrast_factor=1.6,\n",
    "        saturation_factor=1.6,\n",
    "    ),\n",
    "    \"hflip\": imaugs.HFlip(),\n",
    "    \"perspective_transform\": imaugs.PerspectiveTransform(),\n",
    "    \"rotate\": imaugs.Rotate(degrees=50),\n",
    "    \"vflip\": imaugs.VFlip(),\n",
    "    \"overlay_emoji\": imaugs.OverlayEmoji(y_pos=0.3, emoji_size=0.8),\n",
    "    \"overlay_text\": imaugs.OverlayText(font_size=0.5, x_pos=0.2, y_pos=0.1),\n",
    "    \"overlay_stripes\": imaugs.OverlayStripes(\n",
    "        line_angle=-30,\n",
    "        line_density=0.9,\n",
    "        line_width=0.4,\n",
    "        line_type=\"dashed\",\n",
    "    ),\n",
    "    \"meme_format\": imaugs.MemeFormat(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images():\n",
    "    with open(data_table_path) as data_table_file:\n",
    "        data_table = json.load(data_table_file)\n",
    "            \n",
    "    df = pd.DataFrame(data_table[\"data\"])\n",
    "    df.columns = [\"filepath\", \"class\", \"class_name\"]\n",
    "    df[\"filepath\"] = df[\"filepath\"].apply(\n",
    "        lambda path: os.path.basename(os.path.dirname(path))\n",
    "    )\n",
    "    df = df.drop_duplicates()\n",
    "    class_dir_to_id = dict(\n",
    "        zip(df[\"filepath\"], [str(c) for c in df[\"class\"]]),\n",
    "    )\n",
    "        \n",
    "    sampled_test_images = []\n",
    "    image_path_to_class_id = {}\n",
    "    class_id_to_image_paths = {}\n",
    "    for class_id in os.listdir(dataset_dir):\n",
    "        class_dir = os.path.join(dataset_dir, class_id)\n",
    "        if data_table_path is not None:\n",
    "            class_id = class_dir_to_id[class_id]\n",
    "        image_paths = os.listdir(class_dir)\n",
    "\n",
    "        sampled_images = random.sample(image_paths, k=2)\n",
    "        sampled_test_images.extend(\n",
    "            [os.path.join(class_dir, image) for image in sampled_images]\n",
    "        )\n",
    "        image_path_to_class_id.update(\n",
    "            {path : class_id for path in sampled_test_images[-2:]}\n",
    "        )\n",
    "        class_id_to_image_paths[int(class_id)] = sampled_test_images[-2:]\n",
    "        \n",
    "    sampled_test_images = random.sample(sampled_test_images, k=num_images)\n",
    "    print(f\"Sampled {num_images} images to evaluate on\")\n",
    "    return (\n",
    "        sampled_test_images,\n",
    "        image_path_to_class_id,\n",
    "        class_id_to_image_paths,\n",
    "    )\n",
    "\n",
    "\n",
    "def augment_images(images, dataset, num_images=num_images):\n",
    "    num_images = num_images or len(images)\n",
    "    num_augs = len(augmentations.keys())\n",
    "    print(f\"Augmenting {num_images} images using {num_augs} augmentations\")\n",
    "    \n",
    "    if not os.path.exists(aug_dataset_dir):\n",
    "        os.mkdir(aug_dataset_dir)\n",
    "\n",
    "    aug_images = {}\n",
    "    for i, image in enumerate(images[:num_images]):\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Augmented {i + 1}/{len(images)} images\")\n",
    "            \n",
    "        aug_images_dict = {}\n",
    "        for aug_name, aug in augmentations.items():\n",
    "            aug_fp = os.path.join(\n",
    "                aug_dataset_dir,\n",
    "                f\"{image.split('/')[-1].split('.')[0]}_{aug_name}.png\",\n",
    "            )\n",
    "            aug_images_dict[aug_name] = aug_fp\n",
    "            if os.path.exists(aug_fp):\n",
    "                continue\n",
    "                \n",
    "            eval_transform = transforms.Compose(\n",
    "                base_transforms[:1] + [aug] + base_transforms[1:]\n",
    "            )\n",
    "            save_image(eval_transform(image), aug_fp)\n",
    "        aug_images[image] = aug_images_dict\n",
    "\n",
    "    return aug_images\n",
    "\n",
    "\n",
    "def get_model(name):\n",
    "    if name == \"efficientnet_l2\":\n",
    "        model = timm.create_model(\"tf_efficientnet_l2_ns\", pretrained=False)\n",
    "        model.load_state_dict(\n",
    "            torch.load(\n",
    "                os.path.join(\n",
    "                    precomputed_model_metrics_dir,\n",
    "                    \"tf_efficientnet_l2_ns-df73bb44.pth\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        model = (\n",
    "            timm.create_model(name, pretrained=True)\n",
    "            if isinstance(name, str)\n",
    "            else name(pretrained=True)\n",
    "        )\n",
    "\n",
    "    model.eval()\n",
    "    model = model.half()\n",
    "    model.to(devices[1])\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_one_batch(\n",
    "    sampled_images_batch,\n",
    "    aug_sampled_images,\n",
    "    aug_function,\n",
    "    image_path_to_class_id,\n",
    "    model,\n",
    "    custom_model=False,\n",
    "):\n",
    "    to_tensor = transforms.Compose(\n",
    "        custom_model_transforms if custom_model else base_transforms\n",
    "    )\n",
    "    aug_sampled_tensors = [to_tensor(img) for img in aug_sampled_images]\n",
    "    aug_sampled_tensors = torch.stack(aug_sampled_tensors, dim=0)\n",
    "    aug_sampled_tensors = aug_sampled_tensors.half().to(devices[1])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_results = model(aug_sampled_tensors)\n",
    "\n",
    "    aug_sampled_tensors.to(\"cpu\")\n",
    "    probabilities = torch.nn.functional.softmax(model_results, dim=1)\n",
    "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(top5_prob)):\n",
    "        class_synset_id = os.path.basename(\n",
    "            os.path.dirname(sampled_images_batch[i]),\n",
    "        )\n",
    "        class_id = int(image_path_to_class_id[sampled_images_batch[i]])\n",
    "        metadata = []\n",
    "        aug_function(Image.open(sampled_images_batch[i]), metadata=metadata)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"ground_truth_id\": class_id,\n",
    "                \"filepath\": sampled_images_batch[i],\n",
    "                \"is_top1_pred\": class_id == top5_catid[i][0].item(),\n",
    "                \"is_top5_pred\": class_id in top5_catid[i],\n",
    "                \"intensity\": metadata[-1][\"intensity\"],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_model_on_augs(\n",
    "    aug_name,\n",
    "    aug_function,\n",
    "    sampled_test_images,\n",
    "    aug_sampled_images,\n",
    "    image_path_to_class_id,\n",
    "    model,\n",
    "    batch,\n",
    "    custom_model=False,\n",
    "    max_images_to_process=num_images,\n",
    ") -> pd.DataFrame:\n",
    "    num_batches = math.ceil(len(sampled_test_images) / batch)\n",
    "    num_batches = (\n",
    "        num_batches\n",
    "        if max_images_to_process is None\n",
    "        else min(num_batches, math.ceil(max_images_to_process / batch))\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for i in range(num_batches):\n",
    "        sampled_test_img = sampled_test_images[i * batch : (i + 1) * batch]\n",
    "        aug_img = sampled_test_img if aug_name is None else [\n",
    "            aug_sampled_images[img][aug_name] for img in sampled_test_img\n",
    "        ]\n",
    "        results.extend(\n",
    "            evaluate_one_batch(\n",
    "                sampled_test_img,\n",
    "                aug_img,\n",
    "                aug_function,\n",
    "                image_path_to_class_id,\n",
    "                model,\n",
    "                custom_model,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_metrics(base: pd.DataFrame, aug: pd.DataFrame):\n",
    "    metrics = []\n",
    "    intensity = f\"{aug['intensity'][0]:.2f}\"\n",
    "    for n in {1, 5}:\n",
    "        base_n = base[f\"is_top{n}_pred\"]\n",
    "        aug_n = aug[f\"is_top{n}_pred\"]\n",
    "\n",
    "        xor_results = aug_n ^ base_n\n",
    "        diffs = xor_results[xor_results == True]\n",
    "\n",
    "        base_topn_accuracy = len(base_n[base_n == True]) / len(base_n)\n",
    "        aug_topn_accuracy = len(aug_n[aug_n == True]) / len(aug_n)\n",
    "        metrics.append(aug_topn_accuracy)\n",
    "        metrics = [aug_topn_accuracy - base_topn_accuracy] + metrics\n",
    "    \n",
    "    metrics.append(intensity)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def return_top5_results(img: Image.Image, model) -> Tuple:\n",
    "    transform = transforms.Compose(base_transforms[1:])\n",
    "    tensor = transform(img).half().unsqueeze(0).to(devices[1])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_results = model(tensor)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(model_results, dim=1)\n",
    "    return torch.topk(probabilities, 5)\n",
    "\n",
    "\n",
    "def evaluate_model(model_name, custom_model=False):\n",
    "    # If the precomputed metrics CSVs are available, load from there\n",
    "    # instead of recomputing\n",
    "    if precomputed_model_metrics_dir is not None:\n",
    "        model_name_str = (\n",
    "            model_name\n",
    "            if isinstance(model_name, str)\n",
    "            else getattr(model_name, \"__name__\", \"unnamed_model\")\n",
    "        )\n",
    "        metrics_csv_path = os.path.join(\n",
    "            precomputed_model_metrics_dir,\n",
    "            f\"{model_name_str}_robustness_metrics.csv\",\n",
    "        )\n",
    "        \n",
    "        if (\n",
    "            os.path.exists(metrics_csv_path)\n",
    "            and not recompute_model_metrics\n",
    "        ):\n",
    "            return pd.read_csv(metrics_csv_path)\n",
    "\n",
    "    test_set_dir = dataset_dir\n",
    "    num_sampled_images = len(sampled_test_images)\n",
    "\n",
    "    random.seed(seed)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model = get_model(model_name)\n",
    "    \n",
    "    baseline_df = evaluate_model_on_augs(\n",
    "        None,\n",
    "        imaugs.apply_lambda,\n",
    "        sampled_test_images,\n",
    "        aug_images,\n",
    "        image_path_to_class_id,\n",
    "        model,\n",
    "        batch=batch_size,\n",
    "        custom_model=custom_model,\n",
    "    )\n",
    "\n",
    "    num_augs = len(augmentations.keys())\n",
    "    metrics = []\n",
    "    for i, (aug_name, aug) in enumerate(augmentations.items()):\n",
    "        aug_df = evaluate_model_on_augs(\n",
    "            aug_name,\n",
    "            aug,\n",
    "            sampled_test_images,\n",
    "            aug_images,\n",
    "            image_path_to_class_id,\n",
    "            model,\n",
    "            batch=batch_size,\n",
    "            custom_model=custom_model,\n",
    "        )\n",
    "        print(f\"Evaluated model on {i + 1}/{num_augs} augmentations\")\n",
    "        metrics.append(\n",
    "            tuple([aug_name] + compute_metrics(baseline_df, aug_df)),\n",
    "        )\n",
    "    \n",
    "    metrics.sort(key = lambda tup: tup[1])\n",
    "    metrics = [\n",
    "        tuple([\"NONE\"] + compute_metrics(baseline_df, baseline_df))\n",
    "    ] + metrics\n",
    "\n",
    "    metrics_df = pd.DataFrame(\n",
    "        metrics,\n",
    "        columns=[\n",
    "            \"Augmentation\",\n",
    "            \"Top1 acc change\",\n",
    "            \"Top5 acc change\",\n",
    "            \"Top1 acc\",\n",
    "            \"Top5 acc\",\n",
    "            \"Intensity\",\n",
    "        ],\n",
    "    )\n",
    "    if (\n",
    "        precomputed_model_metrics_dir is not None\n",
    "        and not os.path.exists(metrics_csv_path)\n",
    "    ):\n",
    "        metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "        \n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def plot_metrics(dfs, models, filepath):\n",
    "    num_augs = len(dfs[0][\"Augmentation\"])\n",
    "    df_data = []\n",
    "    for df, model in zip(dfs, models):\n",
    "        df_data.extend(\n",
    "            [\n",
    "                tup\n",
    "                for tup in sorted(\n",
    "                    zip(\n",
    "                        df[\"Augmentation\"],\n",
    "                        df[\"Top5 acc change\"],\n",
    "                        [model] * num_augs,\n",
    "                    ),\n",
    "                    key = lambda tup: tup[1],\n",
    "                )\n",
    "                if tup[0] != \"NONE\"\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "    df = pd.DataFrame(\n",
    "        df_data,\n",
    "        columns=[\"Augmentation\", \"Top5 accuracy change\", \"Model\"],\n",
    "    )\n",
    "    fig = px.bar(\n",
    "        df,\n",
    "        x=\"Augmentation\",\n",
    "        y=\"Top5 accuracy change\",\n",
    "        color=\"Model\",\n",
    "        barmode=\"group\",\n",
    "        height=500,\n",
    "    )\n",
    "    fig.write_image(filepath)\n",
    "    return Image.open(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60549eab",
   "metadata": {},
   "source": [
    "## Sample images to evaluate\n",
    "250 images (unless you changed the `num_images` constant above) are randomly sampled from the directory specified containing the imagenet validation set. These images will be augmented & used to evaluate the robustness of the model in question to the various augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ba0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "(\n",
    "    sampled_test_images,\n",
    "    image_path_to_class_id,\n",
    "    class_id_to_image_paths,\n",
    ") = sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110f113",
   "metadata": {},
   "source": [
    "## Augment images\n",
    "We will now augment the 250 sampled images using each of the 17 augmentations. We will store the augmented images in the directory specified above for this purpose, to avoid having to re-run the augmentations if the notebook is run multiple times.\n",
    "\n",
    "See the cell below for examples of each augmentation. If you want to understand more about how these AugLy augmentations work, please see more [here](https://github.com/facebookresearch/AugLy/tree/main/augly/image)! The full list of augmentations we are evaluating on is:\n",
    "- **Pixel-level** transformations\n",
    "    - `blur`\n",
    "    - `random_noise`\n",
    "    - `sharpen`\n",
    "    - `encoding_quality`\n",
    "    - `change_aspect_ratio`\n",
    "    - `opacity`\n",
    "    - `pixelization`\n",
    "    - `scale`\n",
    "- **Color** transformations\n",
    "    - `color_jitter`\n",
    "- **Spatial** transformations\n",
    "    - `hflip`\n",
    "    - `perspective_transform`\n",
    "    - `rotate`\n",
    "    - `vflip`\n",
    "- **Overlay** transformations\n",
    "    - `overlay_emoji`\n",
    "    - `overlay_text`\n",
    "    - `overlay_stripes`\n",
    "    - `meme_format`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now run all the following augmentations on the sampled images\n",
    "img = class_id_to_image_paths[0][0]\n",
    "print(\"Original image\")\n",
    "display(Image.open(img))\n",
    "for aug_name, aug in augmentations.items():\n",
    "    print(\"---------------\")\n",
    "    print(aug_name)\n",
    "    aug_tensor = transforms.Compose(\n",
    "        custom_model_transforms[:1] + [aug] + custom_model_transforms[1:]\n",
    "    )(img)\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\") as tmpfile:\n",
    "        save_image(aug_tensor, tmpfile.name)\n",
    "        display(Image.open(tmpfile.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment all of the sampled images, write out to aug_dataset_dir\n",
    "# {image_path : {aug_name: aug_image}}\n",
    "aug_images = augment_images(\n",
    "    sampled_test_images, aug_dataset_dir, num_images\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3391150",
   "metadata": {},
   "source": [
    "## Compute changes in top1 & top5 accuracy per augmentation\n",
    "For each model in {VGG16, Resnet152, Efficientnet-L2, \\<Your model\\>}, we compute the difference in accuracy between the 250 unaugmented images & the 250 augmented using **each** augmentation. If this drop in accuracy is greater for augmentation A than augmentation B, then this demonstrates that the model is less robust to augmentation A than augmentation B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9b582",
   "metadata": {},
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_df = evaluate_model(models.vgg16)\n",
    "vgg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19025a9",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_df = evaluate_model(models.resnet152)\n",
    "resnet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826022d3",
   "metadata": {},
   "source": [
    "### Efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_df = evaluate_model(\"efficientnet\")\n",
    "efficient_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76e874",
   "metadata": {},
   "source": [
    "### Your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_df = evaluate_model(model_name, custom_model=True)\n",
    "model_4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f4c023",
   "metadata": {},
   "source": [
    "## Plot metrics\n",
    "Here we plot the change in top5 accuracy for **each model** caused by **each augmentation**, computed above. You can thus see how the models \"stack up\" against each other: VGG & Resnet are similarly non-robust to most augmentations; Efficientnet-L2 is much more robust to all augmentations, but its biggest weakness is pixel-level augmentations like `blur` & `rotate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502314da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top5 accuracy ∆ of the model in question caused by different\n",
    "# augmentations compared to VGG, Resnet, & Efficientnet\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    model_name_str = (\n",
    "        model_name\n",
    "        if isinstance(model_name, str)\n",
    "        else getattr(model_name, \"__name__\", \"Unnamed_model\")\n",
    "    )\n",
    "    plot = plot_metrics(\n",
    "        [vgg_df, resnet_df, efficient_df, model_4_df],\n",
    "        [\"VGG16\", \"Resnet152\", \"Efficientnet-L2\", model_name_str.title()],\n",
    "        os.path.join(tempdir, \"plot.jpg\"),\n",
    "    )\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fb5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isc",
   "language": "python",
   "name": "isc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
